{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement learning\n",
    "\n",
    "![Image](https://www.kdnuggets.com/images/reinforcement-learning-fig1-700.jpg)\n",
    "\n",
    "Reinforcement learning (RL) is an area of machine learning concerned with how an agents ought to take actions in an environment so as to maximize some notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning. For any problem to solved using reinforcement learning,we need to define following things-\n",
    "\n",
    "  - State\n",
    "  - Action\n",
    "  - Agent\n",
    "  - Reward/Penalty\n",
    "  - Environment\n",
    "  - Policy\n",
    "  \n",
    "##### State\n",
    " A state is a concrete and immediate situation in which the agent finds itself. In recommendation system, state is the previous history of the user\n",
    " \n",
    "##### Action\n",
    "In recommendation system, action is the items we are recommending to a user\n",
    "\n",
    "##### Agent\n",
    "Agent is our recommendation system\n",
    "\n",
    "##### Reward/Penalty\n",
    "Reward/Penalty is the feedback which the agent gets after taking an action in a certain state\n",
    "\n",
    "##### Environment\n",
    "For every RL problem to be coded, you need to code your environment, It basically consist the action state and next_state after that action relation. In a  state, agent recommends an item and if that item is clicked then user state changes. That is what envirnment consists of.state-action-feedback-next_state\n",
    "We have designed our own environment for a Recommendation system, how  will state change from one state to other after taking action. **[OpenAI gym](https://gym.openai.com/)**   library provides environment for various problems. We can also edit those environment according to our problem, but it's mostly related to Robotics, gaming. For our problem formulation I wrote some functions to make our own environment.\n",
    "\n",
    "##### Value Function (Ï€)\n",
    "The value function is the strategy that the agent employs to determine the next action based on the current state. It maps states to actions, the actions that promise the highest reward.\n",
    "\n",
    "### Epsilon-greedy Q-learning Algorithm\n",
    "The very basic algorithm of reinforcement learning is Q learning. As reinforcement learning has property of explore and exploit, we introduce **epsilon greedy** exploration method so it's Epsilon greedy Q learning. In this algorithm, for state-action mapping as per the policy, we maintain a Q table. **Rows**-*State*,**Columns**-*Action*. Cells contain the Q value of the state action pairs.For further one can get to know from the [link](https://adventuresinmachinelearning.com/reinforcement-learning-tutorial-python-keras/) provided.\n",
    "\n",
    "| State | Action1 | Action2 | .....Action-N|\n",
    "| ------ | ------ |-------| -----|\n",
    "| State1 | Q-value | Q-value | Q-value |\n",
    "| State2 | Q-value | Q-value | Q-value |\n",
    "| State-N  | Q-value | Q-value | Q-value |\n",
    "\n",
    "What is Q value?\n",
    "\n",
    "![image](https://cdn-media-1.freecodecamp.org/images/s39aVodqNAKMTcwuMFlyPSy76kzAmU5idMzk)\n",
    "\n",
    "How to calculate Q values?\n",
    "\n",
    "![Image](https://developer.ibm.com/developer/articles/cc-reinforcement-learning-train-software-agent/images/fig03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example\n",
    "We will consider movie recommendation system for demo purpose\n",
    "\n",
    "##### Challenges\n",
    "As we can see, if we go for Q learning algorithm, we need to maintain Q table for action state mapping.In real scenarion, we have thousands of items to recommend and if we take previous three history of user as state then, nC3 then there will be huge number of state which can't be maintained in one table.\n",
    "\n",
    "##### Solution\n",
    "\n",
    "To deal with this problem, I decided to make a multiple table according to it's genre. The number of table is equal to number of genres in the data. As every article has it's genre, We take the article of same genre and forms it's combination in its table respectively for all genres. But still we will be having lots of states if we follow **nC3**, so instead of that, I stored **one** and **nC2** of it.We take state as three previous history, find the genre of each history article and then look into that table.This approach has not been followed by anyone till now, this is our approach which we found for scaling the Q learning algorithm.\n",
    "\n",
    "##### Example-\n",
    "\n",
    "**State=[movie1, movie2,movie3]**\n",
    "\n",
    "After this we form table using state .Each row of the table is a sub state of the State.\n",
    "\n",
    "**table--**\n",
    "[movie1, movie2,genre4, State_Space4,Q_table4,23]\n",
    "[movie3,genre2, State_Space2,Q_table2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required Python package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data acquisition and processing\n",
    "movie_data=pd.read_csv('Movie_Genre.csv')\n",
    "movie_count=movie_data.groupby('genres')['movieId'].count()\n",
    "movie_count=movie_count.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of movies\n",
    "movie=movie_data['title']\n",
    "movie=list(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify each movie into its genre and form a genre table from data, columns - Genre name; Rows - movie_ID\"\"\"\n",
    "d=[]\n",
    "# movie_count stores the types of genre and no of ID of each genre in data\n",
    "for i in range(0,len(movie_count)):\n",
    "    # making column of the genre and add all the movieID     \n",
    "    d.append(movie_data['movieId'][movie_data['genres'] == movie_count['genres'][i]])\n",
    "    d[i]=pd.DataFrame(d[i])\n",
    "    d[i]=d[i].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,11):    \n",
    "    d[i]=d[i].rename(columns={'movieId':movie_count['genres'][i]})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=d[0]\n",
    "for i in range(1,len(d)):\n",
    "    data=pd.concat([data,d[i]],join='outer',axis=1)\n",
    "    \n",
    "data=data.drop(columns=['index'])\n",
    "genre=data.columns\n",
    "genre_data=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie ID action space from where we recommend \"\"\"\n",
    "movie_Id=movie_data['movieId']\n",
    "movie_Id=list(movie_Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RL has State Space of each genre\"\"\"\n",
    "State_Space_class1=[]\n",
    "State_Space_class2=[]\n",
    "State_Space_class3=[]\n",
    "State_Space_class4=[]\n",
    "State_Space_class5=[]\n",
    "State_Space_class6=[]\n",
    "State_Space_class7=[]\n",
    "State_Space_class8=[]\n",
    "State_Space_class9=[]\n",
    "State_Space_class10=[]\n",
    "State_Space_class11=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Q table for each genre with zero\n",
    "class1_Table=np.zeros([0])\n",
    "class2_Table=np.zeros([0])\n",
    "class3_Table=np.zeros([0])\n",
    "class4_Table=np.zeros([0])\n",
    "class5_Table=np.zeros([0])\n",
    "class6_Table=np.zeros([0])\n",
    "class7_Table=np.zeros([0])\n",
    "class8_Table=np.zeros([0])\n",
    "class9_Table=np.zeros([0])\n",
    "class10_Table=np.zeros([0])\n",
    "class11_Table=np.zeros([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for calling required table and state_space and mapping\n",
    "Dict = {'State_Space_1': State_Space_class1,\n",
    "        'State_Space_2': State_Space_class2,\n",
    "        'State_Space_3': State_Space_class3,\n",
    "        'State_Space_4': State_Space_class4,\n",
    "        'State_Space_5': State_Space_class5,\n",
    "        'State_Space_6': State_Space_class6,\n",
    "        'State_Space_7': State_Space_class7,\n",
    "        'State_Space_8': State_Space_class8,\n",
    "        'State_Space_9': State_Space_class9,\n",
    "        'State_Space_10': State_Space_class10,\n",
    "        'State_Space_11': State_Space_class11,\n",
    "        'class1':class1_Table,\n",
    "        'class2':class2_Table,\n",
    "        'class3':class3_Table,\n",
    "        'class4':class4_Table,\n",
    "        'class5':class5_Table,\n",
    "        'class6':class6_Table,\n",
    "        'class7':class7_Table,\n",
    "        'class8':class8_Table,\n",
    "        'class9':class9_Table,\n",
    "        'class10':class10_Table,\n",
    "        'class11':class11_Table}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for calling required table,state_space, Genre and mapping\n",
    "Dict2={'State_Space':['State_Space_1','State_Space_2','State_Space_3','State_Space_4','State_Space_5','State_Space_6','State_Space_7','State_Space_8','State_Space_9','State_Space_10','State_Space_11'],\n",
    "       'Table':['class1','class2','class3','class4','class5','class6','class7','class8','class9','class10','class11'],\n",
    "       'Genre':[movie_count['genres']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating State_Space\n",
    "for i in range(0,len(movie_count)):\n",
    "    Dict[Dict2['State_Space'][i]].append(list(it.combinations(movie_data['movieId'][movie_data['genres'] == movie_count['genres'][i]],1)))\n",
    "    Dict[Dict2['State_Space'][i]].append(list(it.combinations(movie_data['movieId'][movie_data['genres'] == movie_count['genres'][i]],2)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and initialize Q table of each genre\"\"\"\n",
    "for i in range(0,len(movie_count)):    \n",
    "    Dict[Dict2['Table'][i]]=np.zeros([len(Dict[Dict2['State_Space'][i]][0])+len(Dict[Dict2['State_Space'][i]][1]),len(movie)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let S be a state of user, Finding index of the state of the user\n",
    "Index=[]\n",
    "def INITIAL_STATE_INDEX(S,State_Space_name):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    S (tuple): State - previous history [movies]\n",
    "    State_Space_name - as we have divided according to genre, so goes the state space of that genre\n",
    "    Returns:\n",
    "    Index:Index of that state in State_Space/table row\n",
    "    \"\"\"\n",
    "    Secondary_State=[]\n",
    "    n=len(S)\n",
    "    State_Space=Dict[State_Space_name]\n",
    "    #Storing variation of S as rearrangement matters\n",
    "    Secondary_State=tuple(list(it.permutations(S, n)))\n",
    "    # As our state space contains 1,2 combinations of the ID, in seperate list so that is decided by n to which list to search \n",
    "    if n==1:\n",
    "        for i in range(0,len(Secondary_State)):\n",
    "            if Secondary_State[i] in State_Space[0]:\n",
    "                Index.append(State_Space[0].index(Secondary_State[i]))\n",
    "                break\n",
    "            # just to avoid error if item is not present I have put esle statement, But that condition will not occur\n",
    "            else :\n",
    "                Index.append(0)\n",
    "        return(Index[0])\n",
    "\n",
    "    else:\n",
    "        for i in range(0,len(Secondary_State)):\n",
    "            if Secondary_State[i] in State_Space[1]:\n",
    "                Index.append(State_Space[1].index(Secondary_State[i])+len(State_Space[0]))\n",
    "                break\n",
    "            # just to avoid error if item is not present I have put esle statement, But that condition will not occur     \n",
    "            else:\n",
    "                Index.append(0)\n",
    "        return(Index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently S contaions only previous history of user\n",
    "# New We need to find the genre of each history like - its [genre, table, state_space, its index in state space]\n",
    "# Preprocess function to perform above operation\n",
    "       \n",
    "table=[]\n",
    "table3=[]\n",
    "def PREPROCESS(S):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    S (tuple): State - previous history [movies]\n",
    "    Returns:\n",
    "    table: table that contains [movies, genre,  state_space, table, its row in that table]\n",
    "    \"\"\"\n",
    "    # movie genre[genre of movie, movie name] in seperate rows for each genre type\n",
    "    movies_genre=[]\n",
    "    # genre_data reads all class and there titles from  csv file\n",
    "    for i in range(0,len(S)):\n",
    "        for col in genre_data.columns:\n",
    "            if S[i] in list(genre_data[col]):\n",
    "                movies_genre.append((col,S[i]))\n",
    "    # Table contaion [movie1,....movie_i, class of movies in it]\n",
    "    # Now from movie genre, look for the table, we combine the id of same genre together and different genre in different row of tabe     \n",
    "    f=0\n",
    "    for i in range(0,len(movies_genre)):\n",
    "        r=[]\n",
    "        c=movies_genre[i][0]\n",
    "        for j in range(0,len(movies_genre)):\n",
    "\n",
    "            if movies_genre[j][0]==c:\n",
    "                r.append(movies_genre[j][1])\n",
    "        r.append(c)\n",
    "        r=tuple(r)\n",
    "        table3.append(r)\n",
    "        f = 0\n",
    "        for k in range(0,len(table)):\n",
    "            if table[k][-1]==table3[-1][-1]:\n",
    "                f=1\n",
    "        if f==0:\n",
    "            table.append(r)\n",
    "    table3.clear()\n",
    "    # now table contains [movies,class of movies]\n",
    "    # Then we find its statespace, table and row\n",
    "    for j in range(0,len(table)):\n",
    "        for i in range(0,len(Dict2['Genre'][0])):\n",
    "            if table[j][-1] == Dict2['Genre'][0][i]:\n",
    "                table[j]=list(table[j])\n",
    "                table[j].append(Dict2['State_Space'][i])\n",
    "                table[j].append(Dict2['Table'][i])\n",
    "\n",
    "    # now if all the movie is of same genre len(S) will be three, but our state space does not have 3 combinations of it\n",
    "    # so we break it into 3C2 combinations and search for it in state space          \n",
    "    if len(table)==1 and len(table[0][0:-3])==3:\n",
    "        t=table.copy()\n",
    "        table.clear()\n",
    "        Secondary_State2=[]\n",
    "        S1=t[0][0:-3]\n",
    "        z=[]\n",
    "        Secondary_State2=tuple(list(it.combinations(S1, 2)))\n",
    "        for i in range(0,3):\n",
    "            s=Secondary_State2[i]\n",
    "            z.extend([s[0],s[1],t[0][3],t[0][4],t[0][5]])\n",
    "            table.append(z[-5:])\n",
    "        z.clear()\n",
    "    state=[]\n",
    "    # after that we find the row of that state in Q table for Q update and taking decision for recommendation\n",
    "    for i in range(0,len(table)):\n",
    "        state.append(INITIAL_STATE_INDEX(table[i][0:-3],table[i][-2]))\n",
    "        table[i].extend([state[-1]])\n",
    "        state.remove(state[-1])\n",
    "        Index.remove(Index[-1])    \n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table returned from it will be of form - [[movie_Ids,genre,State_Space_name,Q_Table-Name,row of Q table containing that state],     [movie_Ids,genre,State_Space_name,Q_Table-Name,row of Q table containing that state]] \n",
    "# now if the user clicks the movie it means he/she has wathced the movie and hence user state will change\n",
    "# NEW_STATE changes the user state according to the click of  user\n",
    "\n",
    "# NEW_STATE  function  is used to find the next state after action is taken\n",
    "def NEW_STATE(S,action_idx):\n",
    "    New_State=(S[1],S[2],action_idx)\n",
    "    return (New_State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the index of present state\n",
    "present_ind=[]\n",
    "def PRESENT_INDEX(S):\n",
    "    for i in range(0,len(S)):\n",
    "        present_ind.append(S[i])\n",
    "    return(present_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For next recommendation of the same state, as a single state many have 2-3 substate so, for 1st state if some recommendation\n",
    "# is given, that is stored in Rec_List, so in next sub state we have to remove those from recommendation list otherwise there may be repeated recommendation\n",
    "rec_ind=[]\n",
    "def REC_INDEX(S):\n",
    "    for i in range(0,len(S)):\n",
    "        rec_ind.append(S[i])\n",
    "    return(rec_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to capture and update Q values\n",
    "# if user clicks on the recommended movie then we assign reward\n",
    "# Q values of the clicked movies are updated accordingly in their respective Q TABLE_UPDATE\n",
    "# UPDATE_CLICK_Q_VALUE it updates the Q valus of the clicked movies\n",
    "def UPDATE_CLICK_Q_VALUE(reward,Click):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    Reward(Integer): Reward value, This function is called only after user clicks the recommendation and reward is given to update the Q value\n",
    "    Click(List): We provide list of recommendation, Click list contains the index of movies clicled by user from recommendation list\n",
    "    Returns:\n",
    "    NULL:Update Q values in respective table and update the state of the user\n",
    "    \"\"\"\n",
    "    global table\n",
    "    global S1\n",
    "    S1=list(S1)\n",
    "    S=S1.copy()\n",
    "    for i in range(0,len(Click)):\n",
    "        # as we provide recommendation according to substate, maximum of 3 recommendation is provided, so if user clcik in any of it, we need to know from which substate it was recommended to update the state Q_value accordingly\n",
    "        # K is that value, Click stores the index of the click item in the Rec_List from that we decide to which substate that recommendation belongs to       \n",
    "        n=Click[i]\n",
    "        if n==0:\n",
    "            k=0\n",
    "        elif n==1:\n",
    "            k=1\n",
    "        else:\n",
    "            if len(table2)==3:\n",
    "                k=2\n",
    "            else:\n",
    "                k=len(table2)-1\n",
    "        # Now we find the row and column where we have to update the Q value            \n",
    "        #those values are stored in the table formed by PREPROCESS function        \n",
    "        column=Action[Click[i]]-1\n",
    "        row=table2[k][-1]\n",
    "        old_value = Dict[table2[k][-2]][row,column]\n",
    "        movie_name=Action[Click[i]]\n",
    "        # after user action we have to form the new state, new state max value is used to update the Q value\n",
    "        # as this algorithm looks for the future reward, so we need to find the new state      \n",
    "        new_S=NEW_STATE(S1,Action[Click[i]])\n",
    "        # from new state, we have substate in a State, so we need to see our substate has gone to which new substate it belongs\n",
    "        # we take the max Q value of that next substate form Q update, that next sub state is found by calling the PREPROCES function for new State formed      \n",
    "        PREPROCESS(new_S)\n",
    "        for j in range(0,len(table)):\n",
    "            if movie_name in table[j][0:-4]:\n",
    "                next_state_index=table[j][-1]\n",
    "                next_max = np.max(Dict[table[j][-2]][next_state_index])\n",
    "        new_value = (1 - alpha) * old_value + alpha *(reward + gamma * (next_max-old_value))\n",
    "        Dict[table2[k][-2]][row,column] = new_value\n",
    "        # after all the updates we update the state of the user  \n",
    "        S1=new_S\n",
    "        table.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE_NOT_CLICK_Q_VALUE it updates the Q valus of the Not_clicked movies\"\"\"\n",
    "def UPDATE_NOT_CLICK_Q_VALUE(penalty,Not_Click):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    Reward: Negative reward, as recommendation is ignored, Updates the Q value\n",
    "    Not_Click(List) - We provide list of recommendation, Not_Click list contains the index of movies not clicled by user from recommendation list\n",
    "    Returns:\n",
    "    NULL: Update Q values in the respective tables\n",
    "    \"\"\"\n",
    "    penalty= -penalty\n",
    "    # K value same as explaind in the above function\n",
    "    for i in range(0,len(Not_Click)):\n",
    "        n=Not_Click[i]\n",
    "        if n==0:\n",
    "            k=0\n",
    "        elif n==1:\n",
    "            k=1\n",
    "        else:\n",
    "            if len(table2)==3:\n",
    "                k=2\n",
    "            else:\n",
    "                k=len(table2)-1\n",
    "        # Update of the Q value    \n",
    "        column=Action[Not_Click[i]]-1\n",
    "        row=table2[k][-1]\n",
    "        old_value = Dict[table2[k][-2]][row,column]\n",
    "        next_max=old_value\n",
    "        new_value = (1 - alpha) * old_value + alpha *(penalty + gamma * (next_max-old_value))\n",
    "        Dict[table2[k][-2]][row,column]=new_value\n",
    "        table.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "alpha = 0.8\n",
    "gamma = 0.4\n",
    "epsilon = 0.3\n",
    "Action=[]\n",
    "Rec_List=[]\n",
    "# Recommendation according to states takes input as table[i]\n",
    "def RECOMMENDATION(List_I):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    table[i]:table formed by PREPROCESSED function, stores Substate, its genre, its table and row of the sub_state in that table\n",
    "    Returns:\n",
    "    Recommendation: Recommendation for that Sub_State\n",
    "    \"\"\"\n",
    "    global present_ind\n",
    "    global S1\n",
    "    S=List_I[0:-4]\n",
    " \n",
    "    S_ind=PRESENT_INDEX(List_I)\n",
    "    S_ind=set(S_ind)\n",
    "    day=set(movie_Id)\n",
    "    if len(Rec_List)!=0:\n",
    "        # removes the item from recommendation list if previously recommended in substate of same state    \n",
    "        Rec_List_ind=REC_INDEX(Rec_List)\n",
    "        Rec_List_ind=set(Rec_List_ind)\n",
    "        rec1=day-S_ind\n",
    "        rec=rec1-Rec_List_ind\n",
    "        Rec_List_ind=list(Rec_List_ind)\n",
    "    else:\n",
    "        rec=day-S_ind\n",
    "    rec=list(rec)\n",
    "    S_ind=list(S_ind)\n",
    "    present_ind.clear()\n",
    "    rec_ind.clear()\n",
    "      \n",
    "    state = List_I[-1] #row of Qtable as stored in table \n",
    "    # check whether to explore or exploit\n",
    "    #explore\n",
    "    if random.uniform(0, 1) <= epsilon or np.argmax(Dict[List_I[-2]][state])<= epsilon:\n",
    "    # Check the action space\n",
    "        action1=random.choice(rec)\n",
    "        Action.append(action1)\n",
    "\n",
    "    #exploit\n",
    "    else:\n",
    "    # Check the learned values\n",
    "        aa= np.array(Dict[List_I[-2]][state])\n",
    "        idx=aa.argsort()\n",
    "        idx=list(idx)\n",
    "        for i in range(0,len(S_ind)):\n",
    "            idx.remove(movie_Id.index(S_ind[i]))\n",
    "        if len(Rec_List)!=0:\n",
    "            Rec_List_ind=[]\n",
    "            for i in range(0,len(Rec_List)):\n",
    "                Rec_List_ind.append(movie_Id.index(Rec_List[i]))\n",
    "                if Rec_List_ind[-1] in idx:\n",
    "                    idx.remove(Rec_List_ind[i])\n",
    "        Action.append(idx[-1]+1)\n",
    "        \n",
    "    Index.clear()\n",
    "    rec_ind.clear()\n",
    "    return(Action[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single user can be in multiple states a/c to Q_tables so we stack all the recommendation corresponding\n",
    "#each state and create the recommendation List\n",
    "Recommendation_List=[]    \n",
    "def RECOMMENDATION_LIST(S):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    S: State - previous 3 history\n",
    "    Returns:\n",
    "    Recommendation_List: Recommendation from all sub state\n",
    "    \"\"\"\n",
    "    PREPROCESS(S)\n",
    "    for i in range(0,len(table)):\n",
    "        a=RECOMMENDATION(table[i])\n",
    "        if a not in Rec_List:\n",
    "            Rec_List.append(a)\n",
    "    for i in range(0,len(Action)):\n",
    "        Recommendation_List.append(movie[movie_Id.index(Action[i])]) \n",
    "    return Recommendation_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now after user action we need to update the Tables accordingly\n",
    "# TABLE_UPDATE function updates all the related tables update the state of the user\n",
    "# gives back new recommendation list according to the new states\n",
    "# takes input as list Click - which store the index of item from Rec_List which was clicked by user\n",
    "# updates all the q values and form new state and again provide the list of recommendation according to new state\n",
    "Click=[]\n",
    "Not_Click=[]\n",
    "def TABLE_UPDATE(Click):\n",
    "    global Action\n",
    "    global table\n",
    "    global table2\n",
    "    global Not_Click\n",
    "    global S1\n",
    "    Click2=[]\n",
    "    # as only list of clicked items are given, we need to update not_clicked items also, so we create that    \n",
    "    print(len(Click))\n",
    "    for i in range(0,len(Click)):\n",
    "        Click2.append(Action[Click[i]])\n",
    "    Click2=set(Click2)\n",
    "    Action=set(Action)\n",
    "    Not_Click1=Action- Click2\n",
    "    Action=list(Action)\n",
    "    Not_Click1=list(Not_Click1)\n",
    "    for i in range(0,len(Not_Click1)):\n",
    "        if Not_Click1[i] in Action:\n",
    "            Not_Click.append(Action.index(Not_Click1[i]))\n",
    "    #  Not_Clicked item is created\n",
    "    table2=table.copy()\n",
    "    table.clear()\n",
    "    if len(Click)!=0:\n",
    "        UPDATE_CLICK_Q_VALUE(15,Click)\n",
    "        \n",
    "    if len(Not_Click)!=0:   \n",
    "        UPDATE_NOT_CLICK_Q_VALUE(5,Not_Click)\n",
    "        \n",
    "    Action.clear()\n",
    "    table2.clear()\n",
    "    Index.clear()\n",
    "    Rec_List.clear()\n",
    "    Not_Click.clear()\n",
    "    Not_Click1.clear()\n",
    "    Recommendation_List.clear()\n",
    "    Click.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now all updates are done and according to new state of the user, we provide a new list of recommendation to it  \n",
    "\n",
    "# How to run the algorithm\n",
    "# Just call RECOMMENDATION_LIST(S) function, input state of the user   \n",
    "# after user action, click or ignore\n",
    "# TABLE_UPDATE(Click)function input- Click list - contains index of items clicked by the user from the recommendation list provided.   \n",
    "# State contains the movie_Id of the previous 3 movies clicked by user\n",
    "# State is not according to user, but every user to which we have to recommend\n",
    "# will fall in any of the state which we have formed.\n",
    "# for each user, every time he/she comes we need to see his previous 3 history and form state and input in according as written in above line\n",
    "# even if user has one history, it will be able to recommed a better product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To Die For (1995) Comedy Drama Thriller',\n",
       " 'Chungking Express (Chung Hing sam lam) (1994) Drama Mystery Romance',\n",
       " 'Bio-Dome (1996) Comedy']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RECOMMENDATION_LIST((24,54,72))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "# for  training, we need to make bit of changes in the above code\n",
    "# Data for training- State(1,2,3) id of the movie watched as state\n",
    "# item recommended in that state\n",
    "# Data columns-State, Item recommended in that state\n",
    "\n",
    "test_set=pd.read_csv('State_Data.csv')\n",
    "# Count of the state data each state has\n",
    "State_count=test_set.groupby('State')['recommendation'].count()\n",
    "State_count=State_count.reset_index()\n",
    "# State\n",
    "State=test_set.iloc[:,2].values\n",
    "State=list(State)\n",
    "# clicked item in thatstate\n",
    "Recommended=test_set.iloc[:,3].values\n",
    "Recommended=list(Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the RECOMMENDATION_LIST(S) and see the item clicked in it,\n",
    "# now if that clicked item is in the list, we append its index in the Click list\n",
    "# Call TABLE_UPDATE(Click) function to update Q value\n",
    "# How to update -- \n",
    "# we input the State[i] and take recommendation from algorithm,\n",
    "# We check the rec_list, if it contains the clicked itmes, its fine\n",
    "# if it doesnot, then we append that item in the clicked list and update click as well as not clicked items\n",
    "\n",
    "for i in range(0,len(State)):\n",
    "    S1=[]\n",
    "    a=State[i]\n",
    "    b=int(a%1000)\n",
    "    c=int((a/1000)%1000)\n",
    "    d=int((a/1000000))\n",
    "    S1.extend([d,c,b])\n",
    "    RECOMMENDATION_LIST(S1)\n",
    "    Action.clear()\n",
    "    Action.extend(Rec_List)\n",
    "    if Recommended[i] not in Action:\n",
    "       Action.append(Recommended[i]) \n",
    "    Click.append(Action.index(Recommended[i]))\n",
    "    if i%1000==0:\n",
    "        print(\"--i--\",i)    \n",
    "    TABLE_UPDATE(Click) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cdp] *",
   "language": "python",
   "name": "conda-env-cdp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
